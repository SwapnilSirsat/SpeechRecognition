{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upper-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lb\n",
    "import librosa.display as disp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-pressure",
   "metadata": {},
   "source": [
    "## Understanding the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = lb.util.find_files(\"C:/Users/Asus/Desktop/recordings/Forward\",ext = ['wav'])\n",
    "files = np.asarray(files)\n",
    "for sample in files:\n",
    "    x = lb.load(sample,sr = 16000)\n",
    "    x = x[0]\n",
    "    #plt.figure(figsize=(12,4))\n",
    "    #lb.display.waveplot(x, sr=16000)\n",
    "    #X = lb.stft(x)\n",
    "    #Xdb = lb.amplitude_to_db(abs(X))\n",
    "    #plt.figure(figsize=(20, 5))\n",
    "    #lb.display.specshow(Xdb, sr=16000, x_axis='time', y_axis='hz')\n",
    "    #plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-vaccine",
   "metadata": {},
   "source": [
    "## preprocessing of audio signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equipped-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in files:\n",
    "    x = lb.load(sample,sr = 16000)\n",
    "    x = x[0]\n",
    "    #plt.figure(figsize = (14,7))\n",
    "    #lb.display.waveplot(x,sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agreed-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-lender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-morning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-black",
   "metadata": {},
   "source": [
    "## getting things into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cloudy-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "name = \"recording0.wav\"\n",
    "x = lb.load(name,sr=16000)\n",
    "x = x[0]\n",
    "print(type(x))\n",
    "audio = np.empty(80,dtype = type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separate-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for sample in files:\n",
    "    x = lb.load(sample,sr=16000)\n",
    "    x = x[0]\n",
    "    audio[i] = x\n",
    "    i = i+1\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "variable-staff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0585022 , 0.0585022 , 0.05838013, ..., 0.06225586, 0.0256958 ,\n",
      "       0.0440979 ], dtype=float32)\n",
      " array([0.10443115, 0.10443115, 0.10430908, ..., 0.10391235, 0.10003662,\n",
      "       0.09817505], dtype=float32)\n",
      " array([0.20562744, 0.20562744, 0.20544434, ..., 0.20272827, 0.20968628,\n",
      "       0.20562744], dtype=float32)\n",
      " array([0.06454468, 0.06454468, 0.06442261, ..., 0.2111206 , 0.19592285,\n",
      "       0.17651367], dtype=float32)\n",
      " array([0.05352783, 0.05352783, 0.05328369, ..., 0.05566406, 0.05969238,\n",
      "       0.05447388], dtype=float32)\n",
      " array([0.08288574, 0.08288574, 0.08267212, ..., 0.08361816, 0.06921387,\n",
      "       0.07275391], dtype=float32)\n",
      " array([0.02816772, 0.02816772, 0.02789307, ..., 0.06253052, 0.05142212,\n",
      "       0.04031372], dtype=float32)\n",
      " array([0.07168579, 0.07168579, 0.07147217, ..., 0.07629395, 0.08590698,\n",
      "       0.08737183], dtype=float32)\n",
      " array([0.09692383, 0.09692383, 0.09674072, ..., 0.1267395 , 0.11584473,\n",
      "       0.11102295], dtype=float32)\n",
      " array([-0.12658691, -0.12658691, -0.12680054, ..., -0.13244629,\n",
      "       -0.1300354 , -0.11099243], dtype=float32)\n",
      " array([0.22793579, 0.22793579, 0.2277832 , ..., 0.2281189 , 0.21896362,\n",
      "       0.2168274 ], dtype=float32)\n",
      " array([0.30004883, 0.30004883, 0.29971313, ..., 0.30438232, 0.29205322,\n",
      "       0.30337524], dtype=float32)\n",
      " array([0.15264893, 0.15264893, 0.15252686, ..., 0.15274048, 0.14971924,\n",
      "       0.15136719], dtype=float32)\n",
      " array([0.04705811, 0.04705811, 0.04684448, ..., 0.05938721, 0.04830933,\n",
      "       0.05334473], dtype=float32)\n",
      " array([-0.12762451, -0.12762451, -0.12780762, ..., -0.121521  ,\n",
      "       -0.11782837, -0.12762451], dtype=float32)\n",
      " array([0.0737915 , 0.0737915 , 0.0736084 , ..., 0.08395386, 0.07797241,\n",
      "       0.0737915 ], dtype=float32)\n",
      " array([0.3027649 , 0.3027649 , 0.3025818 , ..., 0.31271362, 0.31713867,\n",
      "       0.3036499 ], dtype=float32)\n",
      " array([0.14529419, 0.14529419, 0.14505005, ..., 0.15640259, 0.16751099,\n",
      "       0.1652832 ], dtype=float32)\n",
      " array([-0.10122681, -0.10122681, -0.10144043, ..., -0.11239624,\n",
      "       -0.11239624, -0.11196899], dtype=float32)\n",
      " array([0.04098511, 0.04098511, 0.04083252, ..., 0.04754639, 0.05130005,\n",
      "       0.04589844], dtype=float32)\n",
      " array([0.15686035, 0.15686035, 0.15661621, ..., 0.1668396 , 0.17196655,\n",
      "       0.16952515], dtype=float32)\n",
      " array([0.10400391, 0.10400391, 0.10385132, ..., 0.10778809, 0.11654663,\n",
      "       0.11547852], dtype=float32)\n",
      " array([0.17108154, 0.17108154, 0.17086792, ..., 0.1845398 , 0.1817627 ,\n",
      "       0.17684937], dtype=float32)\n",
      " array([0.18157959, 0.18157959, 0.18136597, ..., 0.18551636, 0.18460083,\n",
      "       0.17559814], dtype=float32)\n",
      " array([0.05804443, 0.05804443, 0.05786133, ..., 0.07324219, 0.06628418,\n",
      "       0.06518555], dtype=float32)\n",
      " array([0.19277954, 0.19277954, 0.19259644, ..., 0.20248413, 0.20526123,\n",
      "       0.20169067], dtype=float32)\n",
      " array([0.118927  , 0.118927  , 0.11868286, ..., 0.11785889, 0.10913086,\n",
      "       0.12557983], dtype=float32)\n",
      " array([0.12982178, 0.12982178, 0.12966919, ..., 0.1312561 , 0.13061523,\n",
      "       0.12338257], dtype=float32)\n",
      " array([0.21878052, 0.21878052, 0.21853638, ..., 0.23675537, 0.22241211,\n",
      "       0.2156372 ], dtype=float32)\n",
      " array([0.16772461, 0.16772461, 0.16751099, ..., 0.15304565, 0.15664673,\n",
      "       0.14987183], dtype=float32)\n",
      " array([0.13537598, 0.13537598, 0.13513184, ..., 0.12615967, 0.11483765,\n",
      "       0.11508179], dtype=float32)\n",
      " array([0.20187378, 0.20187378, 0.20166016, ..., 0.19839478, 0.20812988,\n",
      "       0.20535278], dtype=float32)\n",
      " array([0.09326172, 0.09326172, 0.09301758, ..., 0.08032227, 0.08776855,\n",
      "       0.09231567], dtype=float32)\n",
      " array([0.16378784, 0.16378784, 0.16360474, ..., 0.16320801, 0.15783691,\n",
      "       0.16418457], dtype=float32)\n",
      " array([0.1401062 , 0.1401062 , 0.13989258, ..., 0.14178467, 0.14157104,\n",
      "       0.1479187 ], dtype=float32)\n",
      " array([ 0.00643921,  0.00643921,  0.00616455, ..., -0.00216675,\n",
      "        0.00991821,  0.01501465], dtype=float32)\n",
      " array([0.04473877, 0.04473877, 0.04452515, ..., 0.03143311, 0.03121948,\n",
      "       0.01940918], dtype=float32)\n",
      " array([0.13018799, 0.13018799, 0.12991333, ..., 0.1177063 , 0.12185669,\n",
      "       0.1270752 ], dtype=float32)\n",
      " array([0.17788696, 0.17788696, 0.17758179, ..., 0.19320679, 0.18478394,\n",
      "       0.18807983], dtype=float32)\n",
      " array([0.02191162, 0.02191162, 0.02163696, ..., 0.00686646, 0.01556396,\n",
      "       0.03302002], dtype=float32)\n",
      " array([0.18341064, 0.18341064, 0.18322754, ..., 0.1979065 , 0.19094849,\n",
      "       0.18774414], dtype=float32)\n",
      " array([0.08856201, 0.08856201, 0.0881958 , ..., 0.08432007, 0.18151855,\n",
      "       0.16638184], dtype=float32)\n",
      " array([0.02392578, 0.02392578, 0.02371216, ..., 0.03207397, 0.02529907,\n",
      "       0.01333618], dtype=float32)\n",
      " array([0.1210022 , 0.1210022 , 0.12072754, ..., 0.08181763, 0.15533447,\n",
      "       0.14944458], dtype=float32)\n",
      " array([0.08364868, 0.08364868, 0.08346558, ..., 0.08966064, 0.09869385,\n",
      "       0.09649658], dtype=float32)\n",
      " array([0.13311768, 0.13311768, 0.13296509, ..., 0.12573242, 0.13064575,\n",
      "       0.13345337], dtype=float32)\n",
      " array([0.23690796, 0.23690796, 0.2366333 , ..., 0.23034668, 0.23635864,\n",
      "       0.2347107 ], dtype=float32)\n",
      " array([0.2506714 , 0.2506714 , 0.25045776, ..., 0.26409912, 0.2592163 ,\n",
      "       0.25793457], dtype=float32)\n",
      " array([0.12307739, 0.12307739, 0.12286377, ..., 0.11886597, 0.13220215,\n",
      "       0.1277771 ], dtype=float32)\n",
      " array([0.12112427, 0.12112427, 0.12078857, ..., 0.1402893 , 0.13995361,\n",
      "       0.14190674], dtype=float32)\n",
      " array([0.15811157, 0.15811157, 0.15786743, ..., 0.15994263, 0.17572021,\n",
      "       0.17800903], dtype=float32)\n",
      " array([ 0.05325317,  0.05325317,  0.05288696, ..., -0.03265381,\n",
      "       -0.02532959,  0.00680542], dtype=float32)\n",
      " array([0.10464478, 0.10464478, 0.10427856, ..., 0.128479  , 0.11529541,\n",
      "       0.12298584], dtype=float32)\n",
      " array([-0.07714844, -0.07714844, -0.07745361, ..., -0.09875488,\n",
      "       -0.10296631, -0.0786438 ], dtype=float32)\n",
      " array([0.14212036, 0.14212036, 0.1418457 , ..., 0.15966797, 0.1729126 ,\n",
      "       0.16751099], dtype=float32)\n",
      " array([0.08074951, 0.08074951, 0.08056641, ..., 0.07174683, 0.07077026,\n",
      "       0.08074951], dtype=float32)\n",
      " array([0.1873169 , 0.1873169 , 0.1871643 , ..., 0.19424438, 0.19412231,\n",
      "       0.19567871], dtype=float32)\n",
      " array([0.1354065 , 0.1354065 , 0.13516235, ..., 0.11401367, 0.10821533,\n",
      "       0.10586548], dtype=float32)\n",
      " array([0.15454102, 0.15454102, 0.15426636, ..., 0.16027832, 0.17025757,\n",
      "       0.17626953], dtype=float32)\n",
      " array([0.12857056, 0.12857056, 0.12832642, ..., 0.12762451, 0.1055603 ,\n",
      "       0.09194946], dtype=float32)\n",
      " array([0.26586914, 0.26586914, 0.26553345, ..., 0.24441528, 0.25906372,\n",
      "       0.26315308], dtype=float32)\n",
      " array([0.12573242, 0.12573242, 0.1255188 , ..., 0.13647461, 0.15145874,\n",
      "       0.15127563], dtype=float32)\n",
      " array([0.0944519 , 0.0944519 , 0.09423828, ..., 0.08999634, 0.09844971,\n",
      "       0.08135986], dtype=float32)\n",
      " array([0.17901611, 0.17901611, 0.17877197, ..., 0.16397095, 0.16751099,\n",
      "       0.16574097], dtype=float32)\n",
      " array([0.13858032, 0.13858032, 0.13830566, ..., 0.16018677, 0.14199829,\n",
      "       0.14056396], dtype=float32)\n",
      " array([0.13253784, 0.13253784, 0.1321106 , ..., 0.12869263, 0.13470459,\n",
      "       0.15356445], dtype=float32)\n",
      " array([0.1489563 , 0.1489563 , 0.14871216, ..., 0.16503906, 0.16827393,\n",
      "       0.16043091], dtype=float32)\n",
      " array([0.22546387, 0.22546387, 0.22525024, ..., 0.23547363, 0.22763062,\n",
      "       0.23962402], dtype=float32)\n",
      " array([0.24737549, 0.24737549, 0.24707031, ..., 0.26400757, 0.25280762,\n",
      "       0.24771118], dtype=float32)\n",
      " array([0.06057739, 0.06057739, 0.06033325, ..., 0.02572632, 0.02572632,\n",
      "       0.02349854], dtype=float32)\n",
      " array([0.16766357, 0.16766357, 0.16741943, ..., 0.18225098, 0.18096924,\n",
      "       0.19003296], dtype=float32)\n",
      " array([0.12548828, 0.12548828, 0.12521362, ..., 0.13381958, 0.12576294,\n",
      "       0.12237549], dtype=float32)\n",
      " array([0.18151855, 0.18151855, 0.18127441, ..., 0.16125488, 0.13659668,\n",
      "       0.22131348], dtype=float32)\n",
      " array([0.19744873, 0.19744873, 0.19726562, ..., 0.20535278, 0.20574951,\n",
      "       0.20495605], dtype=float32)\n",
      " array([0.11395264, 0.11395264, 0.1137085 , ..., 0.12966919, 0.13391113,\n",
      "       0.12918091], dtype=float32)\n",
      " array([0.06207275, 0.06207275, 0.06164551, ..., 0.00082397, 0.02151489,\n",
      "       0.02404785], dtype=float32)\n",
      " array([0.11004639, 0.11004639, 0.10983276, ..., 0.13827515, 0.09841919,\n",
      "       0.06747437], dtype=float32)\n",
      " array([0.09399414, 0.09399414, 0.09381104, ..., 0.10461426, 0.10147095,\n",
      "       0.09414673], dtype=float32)\n",
      " array([0.1000061 , 0.1000061 , 0.099823  , ..., 0.10971069, 0.10305786,\n",
      "       0.09469604], dtype=float32)\n",
      " array([0.12103271, 0.12103271, 0.12081909, ..., 0.12887573, 0.12979126,\n",
      "       0.13134766], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "quarterly-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,80):\n",
    "    skl.minmax_scale(audio[i],axis = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "noted-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0585022 , 0.0585022 , 0.05838013, ..., 0.06225586, 0.0256958 ,\n",
      "       0.0440979 ], dtype=float32)\n",
      " array([0.10443115, 0.10443115, 0.10430908, ..., 0.10391235, 0.10003662,\n",
      "       0.09817505], dtype=float32)\n",
      " array([0.20562744, 0.20562744, 0.20544434, ..., 0.20272827, 0.20968628,\n",
      "       0.20562744], dtype=float32)\n",
      " array([0.06454468, 0.06454468, 0.06442261, ..., 0.2111206 , 0.19592285,\n",
      "       0.17651367], dtype=float32)\n",
      " array([0.05352783, 0.05352783, 0.05328369, ..., 0.05566406, 0.05969238,\n",
      "       0.05447388], dtype=float32)\n",
      " array([0.08288574, 0.08288574, 0.08267212, ..., 0.08361816, 0.06921387,\n",
      "       0.07275391], dtype=float32)\n",
      " array([0.02816772, 0.02816772, 0.02789307, ..., 0.06253052, 0.05142212,\n",
      "       0.04031372], dtype=float32)\n",
      " array([0.07168579, 0.07168579, 0.07147217, ..., 0.07629395, 0.08590698,\n",
      "       0.08737183], dtype=float32)\n",
      " array([0.09692383, 0.09692383, 0.09674072, ..., 0.1267395 , 0.11584473,\n",
      "       0.11102295], dtype=float32)\n",
      " array([-0.12658691, -0.12658691, -0.12680054, ..., -0.13244629,\n",
      "       -0.1300354 , -0.11099243], dtype=float32)\n",
      " array([0.22793579, 0.22793579, 0.2277832 , ..., 0.2281189 , 0.21896362,\n",
      "       0.2168274 ], dtype=float32)\n",
      " array([0.30004883, 0.30004883, 0.29971313, ..., 0.30438232, 0.29205322,\n",
      "       0.30337524], dtype=float32)\n",
      " array([0.15264893, 0.15264893, 0.15252686, ..., 0.15274048, 0.14971924,\n",
      "       0.15136719], dtype=float32)\n",
      " array([0.04705811, 0.04705811, 0.04684448, ..., 0.05938721, 0.04830933,\n",
      "       0.05334473], dtype=float32)\n",
      " array([-0.12762451, -0.12762451, -0.12780762, ..., -0.121521  ,\n",
      "       -0.11782837, -0.12762451], dtype=float32)\n",
      " array([0.0737915 , 0.0737915 , 0.0736084 , ..., 0.08395386, 0.07797241,\n",
      "       0.0737915 ], dtype=float32)\n",
      " array([0.3027649 , 0.3027649 , 0.3025818 , ..., 0.31271362, 0.31713867,\n",
      "       0.3036499 ], dtype=float32)\n",
      " array([0.14529419, 0.14529419, 0.14505005, ..., 0.15640259, 0.16751099,\n",
      "       0.1652832 ], dtype=float32)\n",
      " array([-0.10122681, -0.10122681, -0.10144043, ..., -0.11239624,\n",
      "       -0.11239624, -0.11196899], dtype=float32)\n",
      " array([0.04098511, 0.04098511, 0.04083252, ..., 0.04754639, 0.05130005,\n",
      "       0.04589844], dtype=float32)\n",
      " array([0.15686035, 0.15686035, 0.15661621, ..., 0.1668396 , 0.17196655,\n",
      "       0.16952515], dtype=float32)\n",
      " array([0.10400391, 0.10400391, 0.10385132, ..., 0.10778809, 0.11654663,\n",
      "       0.11547852], dtype=float32)\n",
      " array([0.17108154, 0.17108154, 0.17086792, ..., 0.1845398 , 0.1817627 ,\n",
      "       0.17684937], dtype=float32)\n",
      " array([0.18157959, 0.18157959, 0.18136597, ..., 0.18551636, 0.18460083,\n",
      "       0.17559814], dtype=float32)\n",
      " array([0.05804443, 0.05804443, 0.05786133, ..., 0.07324219, 0.06628418,\n",
      "       0.06518555], dtype=float32)\n",
      " array([0.19277954, 0.19277954, 0.19259644, ..., 0.20248413, 0.20526123,\n",
      "       0.20169067], dtype=float32)\n",
      " array([0.118927  , 0.118927  , 0.11868286, ..., 0.11785889, 0.10913086,\n",
      "       0.12557983], dtype=float32)\n",
      " array([0.12982178, 0.12982178, 0.12966919, ..., 0.1312561 , 0.13061523,\n",
      "       0.12338257], dtype=float32)\n",
      " array([0.21878052, 0.21878052, 0.21853638, ..., 0.23675537, 0.22241211,\n",
      "       0.2156372 ], dtype=float32)\n",
      " array([0.16772461, 0.16772461, 0.16751099, ..., 0.15304565, 0.15664673,\n",
      "       0.14987183], dtype=float32)\n",
      " array([0.13537598, 0.13537598, 0.13513184, ..., 0.12615967, 0.11483765,\n",
      "       0.11508179], dtype=float32)\n",
      " array([0.20187378, 0.20187378, 0.20166016, ..., 0.19839478, 0.20812988,\n",
      "       0.20535278], dtype=float32)\n",
      " array([0.09326172, 0.09326172, 0.09301758, ..., 0.08032227, 0.08776855,\n",
      "       0.09231567], dtype=float32)\n",
      " array([0.16378784, 0.16378784, 0.16360474, ..., 0.16320801, 0.15783691,\n",
      "       0.16418457], dtype=float32)\n",
      " array([0.1401062 , 0.1401062 , 0.13989258, ..., 0.14178467, 0.14157104,\n",
      "       0.1479187 ], dtype=float32)\n",
      " array([ 0.00643921,  0.00643921,  0.00616455, ..., -0.00216675,\n",
      "        0.00991821,  0.01501465], dtype=float32)\n",
      " array([0.04473877, 0.04473877, 0.04452515, ..., 0.03143311, 0.03121948,\n",
      "       0.01940918], dtype=float32)\n",
      " array([0.13018799, 0.13018799, 0.12991333, ..., 0.1177063 , 0.12185669,\n",
      "       0.1270752 ], dtype=float32)\n",
      " array([0.17788696, 0.17788696, 0.17758179, ..., 0.19320679, 0.18478394,\n",
      "       0.18807983], dtype=float32)\n",
      " array([0.02191162, 0.02191162, 0.02163696, ..., 0.00686646, 0.01556396,\n",
      "       0.03302002], dtype=float32)\n",
      " array([0.18341064, 0.18341064, 0.18322754, ..., 0.1979065 , 0.19094849,\n",
      "       0.18774414], dtype=float32)\n",
      " array([0.08856201, 0.08856201, 0.0881958 , ..., 0.08432007, 0.18151855,\n",
      "       0.16638184], dtype=float32)\n",
      " array([0.02392578, 0.02392578, 0.02371216, ..., 0.03207397, 0.02529907,\n",
      "       0.01333618], dtype=float32)\n",
      " array([0.1210022 , 0.1210022 , 0.12072754, ..., 0.08181763, 0.15533447,\n",
      "       0.14944458], dtype=float32)\n",
      " array([0.08364868, 0.08364868, 0.08346558, ..., 0.08966064, 0.09869385,\n",
      "       0.09649658], dtype=float32)\n",
      " array([0.13311768, 0.13311768, 0.13296509, ..., 0.12573242, 0.13064575,\n",
      "       0.13345337], dtype=float32)\n",
      " array([0.23690796, 0.23690796, 0.2366333 , ..., 0.23034668, 0.23635864,\n",
      "       0.2347107 ], dtype=float32)\n",
      " array([0.2506714 , 0.2506714 , 0.25045776, ..., 0.26409912, 0.2592163 ,\n",
      "       0.25793457], dtype=float32)\n",
      " array([0.12307739, 0.12307739, 0.12286377, ..., 0.11886597, 0.13220215,\n",
      "       0.1277771 ], dtype=float32)\n",
      " array([0.12112427, 0.12112427, 0.12078857, ..., 0.1402893 , 0.13995361,\n",
      "       0.14190674], dtype=float32)\n",
      " array([0.15811157, 0.15811157, 0.15786743, ..., 0.15994263, 0.17572021,\n",
      "       0.17800903], dtype=float32)\n",
      " array([ 0.05325317,  0.05325317,  0.05288696, ..., -0.03265381,\n",
      "       -0.02532959,  0.00680542], dtype=float32)\n",
      " array([0.10464478, 0.10464478, 0.10427856, ..., 0.128479  , 0.11529541,\n",
      "       0.12298584], dtype=float32)\n",
      " array([-0.07714844, -0.07714844, -0.07745361, ..., -0.09875488,\n",
      "       -0.10296631, -0.0786438 ], dtype=float32)\n",
      " array([0.14212036, 0.14212036, 0.1418457 , ..., 0.15966797, 0.1729126 ,\n",
      "       0.16751099], dtype=float32)\n",
      " array([0.08074951, 0.08074951, 0.08056641, ..., 0.07174683, 0.07077026,\n",
      "       0.08074951], dtype=float32)\n",
      " array([0.1873169 , 0.1873169 , 0.1871643 , ..., 0.19424438, 0.19412231,\n",
      "       0.19567871], dtype=float32)\n",
      " array([0.1354065 , 0.1354065 , 0.13516235, ..., 0.11401367, 0.10821533,\n",
      "       0.10586548], dtype=float32)\n",
      " array([0.15454102, 0.15454102, 0.15426636, ..., 0.16027832, 0.17025757,\n",
      "       0.17626953], dtype=float32)\n",
      " array([0.12857056, 0.12857056, 0.12832642, ..., 0.12762451, 0.1055603 ,\n",
      "       0.09194946], dtype=float32)\n",
      " array([0.26586914, 0.26586914, 0.26553345, ..., 0.24441528, 0.25906372,\n",
      "       0.26315308], dtype=float32)\n",
      " array([0.12573242, 0.12573242, 0.1255188 , ..., 0.13647461, 0.15145874,\n",
      "       0.15127563], dtype=float32)\n",
      " array([0.0944519 , 0.0944519 , 0.09423828, ..., 0.08999634, 0.09844971,\n",
      "       0.08135986], dtype=float32)\n",
      " array([0.17901611, 0.17901611, 0.17877197, ..., 0.16397095, 0.16751099,\n",
      "       0.16574097], dtype=float32)\n",
      " array([0.13858032, 0.13858032, 0.13830566, ..., 0.16018677, 0.14199829,\n",
      "       0.14056396], dtype=float32)\n",
      " array([0.13253784, 0.13253784, 0.1321106 , ..., 0.12869263, 0.13470459,\n",
      "       0.15356445], dtype=float32)\n",
      " array([0.1489563 , 0.1489563 , 0.14871216, ..., 0.16503906, 0.16827393,\n",
      "       0.16043091], dtype=float32)\n",
      " array([0.22546387, 0.22546387, 0.22525024, ..., 0.23547363, 0.22763062,\n",
      "       0.23962402], dtype=float32)\n",
      " array([0.24737549, 0.24737549, 0.24707031, ..., 0.26400757, 0.25280762,\n",
      "       0.24771118], dtype=float32)\n",
      " array([0.06057739, 0.06057739, 0.06033325, ..., 0.02572632, 0.02572632,\n",
      "       0.02349854], dtype=float32)\n",
      " array([0.16766357, 0.16766357, 0.16741943, ..., 0.18225098, 0.18096924,\n",
      "       0.19003296], dtype=float32)\n",
      " array([0.12548828, 0.12548828, 0.12521362, ..., 0.13381958, 0.12576294,\n",
      "       0.12237549], dtype=float32)\n",
      " array([0.18151855, 0.18151855, 0.18127441, ..., 0.16125488, 0.13659668,\n",
      "       0.22131348], dtype=float32)\n",
      " array([0.19744873, 0.19744873, 0.19726562, ..., 0.20535278, 0.20574951,\n",
      "       0.20495605], dtype=float32)\n",
      " array([0.11395264, 0.11395264, 0.1137085 , ..., 0.12966919, 0.13391113,\n",
      "       0.12918091], dtype=float32)\n",
      " array([0.06207275, 0.06207275, 0.06164551, ..., 0.00082397, 0.02151489,\n",
      "       0.02404785], dtype=float32)\n",
      " array([0.11004639, 0.11004639, 0.10983276, ..., 0.13827515, 0.09841919,\n",
      "       0.06747437], dtype=float32)\n",
      " array([0.09399414, 0.09399414, 0.09381104, ..., 0.10461426, 0.10147095,\n",
      "       0.09414673], dtype=float32)\n",
      " array([0.1000061 , 0.1000061 , 0.099823  , ..., 0.10971069, 0.10305786,\n",
      "       0.09469604], dtype=float32)\n",
      " array([0.12103271, 0.12103271, 0.12081909, ..., 0.12887573, 0.12979126,\n",
      "       0.13134766], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-solid",
   "metadata": {},
   "source": [
    "## now premphasizeing the signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "latter-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interim-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-cliff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-junction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-oriental",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-moderator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-chest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-assault",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "latest-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Y = pd.read_csv(\"Book1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cathedral-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "removable-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']\n",
      " ['forward']]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dietary-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "premium-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.0585022 , 0.0585022 , 0.05838013, ..., 0.06225586, 0.0256958 ,\n",
      "       0.0440979 ], dtype=float32)\n",
      " array([0.10443115, 0.10443115, 0.10430908, ..., 0.10391235, 0.10003662,\n",
      "       0.09817505], dtype=float32)\n",
      " array([0.20562744, 0.20562744, 0.20544434, ..., 0.20272827, 0.20968628,\n",
      "       0.20562744], dtype=float32)\n",
      " array([0.06454468, 0.06454468, 0.06442261, ..., 0.2111206 , 0.19592285,\n",
      "       0.17651367], dtype=float32)\n",
      " array([0.05352783, 0.05352783, 0.05328369, ..., 0.05566406, 0.05969238,\n",
      "       0.05447388], dtype=float32)\n",
      " array([0.08288574, 0.08288574, 0.08267212, ..., 0.08361816, 0.06921387,\n",
      "       0.07275391], dtype=float32)\n",
      " array([0.02816772, 0.02816772, 0.02789307, ..., 0.06253052, 0.05142212,\n",
      "       0.04031372], dtype=float32)\n",
      " array([0.07168579, 0.07168579, 0.07147217, ..., 0.07629395, 0.08590698,\n",
      "       0.08737183], dtype=float32)\n",
      " array([0.09692383, 0.09692383, 0.09674072, ..., 0.1267395 , 0.11584473,\n",
      "       0.11102295], dtype=float32)\n",
      " array([-0.12658691, -0.12658691, -0.12680054, ..., -0.13244629,\n",
      "       -0.1300354 , -0.11099243], dtype=float32)\n",
      " array([0.22793579, 0.22793579, 0.2277832 , ..., 0.2281189 , 0.21896362,\n",
      "       0.2168274 ], dtype=float32)\n",
      " array([0.30004883, 0.30004883, 0.29971313, ..., 0.30438232, 0.29205322,\n",
      "       0.30337524], dtype=float32)\n",
      " array([0.15264893, 0.15264893, 0.15252686, ..., 0.15274048, 0.14971924,\n",
      "       0.15136719], dtype=float32)\n",
      " array([0.04705811, 0.04705811, 0.04684448, ..., 0.05938721, 0.04830933,\n",
      "       0.05334473], dtype=float32)\n",
      " array([-0.12762451, -0.12762451, -0.12780762, ..., -0.121521  ,\n",
      "       -0.11782837, -0.12762451], dtype=float32)\n",
      " array([0.0737915 , 0.0737915 , 0.0736084 , ..., 0.08395386, 0.07797241,\n",
      "       0.0737915 ], dtype=float32)\n",
      " array([0.3027649 , 0.3027649 , 0.3025818 , ..., 0.31271362, 0.31713867,\n",
      "       0.3036499 ], dtype=float32)\n",
      " array([0.14529419, 0.14529419, 0.14505005, ..., 0.15640259, 0.16751099,\n",
      "       0.1652832 ], dtype=float32)\n",
      " array([-0.10122681, -0.10122681, -0.10144043, ..., -0.11239624,\n",
      "       -0.11239624, -0.11196899], dtype=float32)\n",
      " array([0.04098511, 0.04098511, 0.04083252, ..., 0.04754639, 0.05130005,\n",
      "       0.04589844], dtype=float32)\n",
      " array([0.15686035, 0.15686035, 0.15661621, ..., 0.1668396 , 0.17196655,\n",
      "       0.16952515], dtype=float32)\n",
      " array([0.10400391, 0.10400391, 0.10385132, ..., 0.10778809, 0.11654663,\n",
      "       0.11547852], dtype=float32)\n",
      " array([0.17108154, 0.17108154, 0.17086792, ..., 0.1845398 , 0.1817627 ,\n",
      "       0.17684937], dtype=float32)\n",
      " array([0.18157959, 0.18157959, 0.18136597, ..., 0.18551636, 0.18460083,\n",
      "       0.17559814], dtype=float32)\n",
      " array([0.05804443, 0.05804443, 0.05786133, ..., 0.07324219, 0.06628418,\n",
      "       0.06518555], dtype=float32)\n",
      " array([0.19277954, 0.19277954, 0.19259644, ..., 0.20248413, 0.20526123,\n",
      "       0.20169067], dtype=float32)\n",
      " array([0.118927  , 0.118927  , 0.11868286, ..., 0.11785889, 0.10913086,\n",
      "       0.12557983], dtype=float32)\n",
      " array([0.12982178, 0.12982178, 0.12966919, ..., 0.1312561 , 0.13061523,\n",
      "       0.12338257], dtype=float32)\n",
      " array([0.21878052, 0.21878052, 0.21853638, ..., 0.23675537, 0.22241211,\n",
      "       0.2156372 ], dtype=float32)\n",
      " array([0.16772461, 0.16772461, 0.16751099, ..., 0.15304565, 0.15664673,\n",
      "       0.14987183], dtype=float32)\n",
      " array([0.13537598, 0.13537598, 0.13513184, ..., 0.12615967, 0.11483765,\n",
      "       0.11508179], dtype=float32)\n",
      " array([0.20187378, 0.20187378, 0.20166016, ..., 0.19839478, 0.20812988,\n",
      "       0.20535278], dtype=float32)\n",
      " array([0.09326172, 0.09326172, 0.09301758, ..., 0.08032227, 0.08776855,\n",
      "       0.09231567], dtype=float32)\n",
      " array([0.16378784, 0.16378784, 0.16360474, ..., 0.16320801, 0.15783691,\n",
      "       0.16418457], dtype=float32)\n",
      " array([0.1401062 , 0.1401062 , 0.13989258, ..., 0.14178467, 0.14157104,\n",
      "       0.1479187 ], dtype=float32)\n",
      " array([ 0.00643921,  0.00643921,  0.00616455, ..., -0.00216675,\n",
      "        0.00991821,  0.01501465], dtype=float32)\n",
      " array([0.04473877, 0.04473877, 0.04452515, ..., 0.03143311, 0.03121948,\n",
      "       0.01940918], dtype=float32)\n",
      " array([0.13018799, 0.13018799, 0.12991333, ..., 0.1177063 , 0.12185669,\n",
      "       0.1270752 ], dtype=float32)\n",
      " array([0.17788696, 0.17788696, 0.17758179, ..., 0.19320679, 0.18478394,\n",
      "       0.18807983], dtype=float32)\n",
      " array([0.02191162, 0.02191162, 0.02163696, ..., 0.00686646, 0.01556396,\n",
      "       0.03302002], dtype=float32)\n",
      " array([0.18341064, 0.18341064, 0.18322754, ..., 0.1979065 , 0.19094849,\n",
      "       0.18774414], dtype=float32)\n",
      " array([0.08856201, 0.08856201, 0.0881958 , ..., 0.08432007, 0.18151855,\n",
      "       0.16638184], dtype=float32)\n",
      " array([0.02392578, 0.02392578, 0.02371216, ..., 0.03207397, 0.02529907,\n",
      "       0.01333618], dtype=float32)\n",
      " array([0.1210022 , 0.1210022 , 0.12072754, ..., 0.08181763, 0.15533447,\n",
      "       0.14944458], dtype=float32)\n",
      " array([0.08364868, 0.08364868, 0.08346558, ..., 0.08966064, 0.09869385,\n",
      "       0.09649658], dtype=float32)\n",
      " array([0.13311768, 0.13311768, 0.13296509, ..., 0.12573242, 0.13064575,\n",
      "       0.13345337], dtype=float32)\n",
      " array([0.23690796, 0.23690796, 0.2366333 , ..., 0.23034668, 0.23635864,\n",
      "       0.2347107 ], dtype=float32)\n",
      " array([0.2506714 , 0.2506714 , 0.25045776, ..., 0.26409912, 0.2592163 ,\n",
      "       0.25793457], dtype=float32)\n",
      " array([0.12307739, 0.12307739, 0.12286377, ..., 0.11886597, 0.13220215,\n",
      "       0.1277771 ], dtype=float32)\n",
      " array([0.12112427, 0.12112427, 0.12078857, ..., 0.1402893 , 0.13995361,\n",
      "       0.14190674], dtype=float32)\n",
      " array([0.15811157, 0.15811157, 0.15786743, ..., 0.15994263, 0.17572021,\n",
      "       0.17800903], dtype=float32)\n",
      " array([ 0.05325317,  0.05325317,  0.05288696, ..., -0.03265381,\n",
      "       -0.02532959,  0.00680542], dtype=float32)\n",
      " array([0.10464478, 0.10464478, 0.10427856, ..., 0.128479  , 0.11529541,\n",
      "       0.12298584], dtype=float32)\n",
      " array([-0.07714844, -0.07714844, -0.07745361, ..., -0.09875488,\n",
      "       -0.10296631, -0.0786438 ], dtype=float32)\n",
      " array([0.14212036, 0.14212036, 0.1418457 , ..., 0.15966797, 0.1729126 ,\n",
      "       0.16751099], dtype=float32)\n",
      " array([0.08074951, 0.08074951, 0.08056641, ..., 0.07174683, 0.07077026,\n",
      "       0.08074951], dtype=float32)\n",
      " array([0.1873169 , 0.1873169 , 0.1871643 , ..., 0.19424438, 0.19412231,\n",
      "       0.19567871], dtype=float32)\n",
      " array([0.1354065 , 0.1354065 , 0.13516235, ..., 0.11401367, 0.10821533,\n",
      "       0.10586548], dtype=float32)\n",
      " array([0.15454102, 0.15454102, 0.15426636, ..., 0.16027832, 0.17025757,\n",
      "       0.17626953], dtype=float32)\n",
      " array([0.12857056, 0.12857056, 0.12832642, ..., 0.12762451, 0.1055603 ,\n",
      "       0.09194946], dtype=float32)\n",
      " array([0.26586914, 0.26586914, 0.26553345, ..., 0.24441528, 0.25906372,\n",
      "       0.26315308], dtype=float32)\n",
      " array([0.12573242, 0.12573242, 0.1255188 , ..., 0.13647461, 0.15145874,\n",
      "       0.15127563], dtype=float32)\n",
      " array([0.0944519 , 0.0944519 , 0.09423828, ..., 0.08999634, 0.09844971,\n",
      "       0.08135986], dtype=float32)\n",
      " array([0.17901611, 0.17901611, 0.17877197, ..., 0.16397095, 0.16751099,\n",
      "       0.16574097], dtype=float32)\n",
      " array([0.13858032, 0.13858032, 0.13830566, ..., 0.16018677, 0.14199829,\n",
      "       0.14056396], dtype=float32)\n",
      " array([0.13253784, 0.13253784, 0.1321106 , ..., 0.12869263, 0.13470459,\n",
      "       0.15356445], dtype=float32)\n",
      " array([0.1489563 , 0.1489563 , 0.14871216, ..., 0.16503906, 0.16827393,\n",
      "       0.16043091], dtype=float32)\n",
      " array([0.22546387, 0.22546387, 0.22525024, ..., 0.23547363, 0.22763062,\n",
      "       0.23962402], dtype=float32)\n",
      " array([0.24737549, 0.24737549, 0.24707031, ..., 0.26400757, 0.25280762,\n",
      "       0.24771118], dtype=float32)\n",
      " array([0.06057739, 0.06057739, 0.06033325, ..., 0.02572632, 0.02572632,\n",
      "       0.02349854], dtype=float32)\n",
      " array([0.16766357, 0.16766357, 0.16741943, ..., 0.18225098, 0.18096924,\n",
      "       0.19003296], dtype=float32)\n",
      " array([0.12548828, 0.12548828, 0.12521362, ..., 0.13381958, 0.12576294,\n",
      "       0.12237549], dtype=float32)\n",
      " array([0.18151855, 0.18151855, 0.18127441, ..., 0.16125488, 0.13659668,\n",
      "       0.22131348], dtype=float32)\n",
      " array([0.19744873, 0.19744873, 0.19726562, ..., 0.20535278, 0.20574951,\n",
      "       0.20495605], dtype=float32)\n",
      " array([0.11395264, 0.11395264, 0.1137085 , ..., 0.12966919, 0.13391113,\n",
      "       0.12918091], dtype=float32)\n",
      " array([0.06207275, 0.06207275, 0.06164551, ..., 0.00082397, 0.02151489,\n",
      "       0.02404785], dtype=float32)\n",
      " array([0.11004639, 0.11004639, 0.10983276, ..., 0.13827515, 0.09841919,\n",
      "       0.06747437], dtype=float32)\n",
      " array([0.09399414, 0.09399414, 0.09381104, ..., 0.10461426, 0.10147095,\n",
      "       0.09414673], dtype=float32)\n",
      " array([0.1000061 , 0.1000061 , 0.099823  , ..., 0.10971069, 0.10305786,\n",
      "       0.09469604], dtype=float32)\n",
      " array([0.12103271, 0.12103271, 0.12081909, ..., 0.12887573, 0.12979126,\n",
      "       0.13134766], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "touched-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(audio[0])\n",
    "dataframe[0] = pd.DataFrame(audio[0])\n",
    "for i in range(1,80):\n",
    "    dataframe[i] = pd.DataFrame(audio[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spread-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.082886</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.071686</td>\n",
       "      <td>0.096924</td>\n",
       "      <td>-0.126587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167664</td>\n",
       "      <td>0.125488</td>\n",
       "      <td>0.181519</td>\n",
       "      <td>0.197449</td>\n",
       "      <td>0.113953</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.121033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.082886</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.071686</td>\n",
       "      <td>0.096924</td>\n",
       "      <td>-0.126587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167664</td>\n",
       "      <td>0.125488</td>\n",
       "      <td>0.181519</td>\n",
       "      <td>0.197449</td>\n",
       "      <td>0.113953</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.121033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058380</td>\n",
       "      <td>0.104309</td>\n",
       "      <td>0.205444</td>\n",
       "      <td>0.064423</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.082672</td>\n",
       "      <td>0.027893</td>\n",
       "      <td>0.071472</td>\n",
       "      <td>0.096741</td>\n",
       "      <td>-0.126801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167419</td>\n",
       "      <td>0.125214</td>\n",
       "      <td>0.181274</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>0.061646</td>\n",
       "      <td>0.109833</td>\n",
       "      <td>0.093811</td>\n",
       "      <td>0.099823</td>\n",
       "      <td>0.120819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.082886</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.071686</td>\n",
       "      <td>0.096924</td>\n",
       "      <td>-0.126587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167664</td>\n",
       "      <td>0.125488</td>\n",
       "      <td>0.181519</td>\n",
       "      <td>0.197449</td>\n",
       "      <td>0.113953</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.121033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.082886</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.071686</td>\n",
       "      <td>0.096924</td>\n",
       "      <td>-0.126587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167664</td>\n",
       "      <td>0.125488</td>\n",
       "      <td>0.181519</td>\n",
       "      <td>0.197449</td>\n",
       "      <td>0.113953</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.121033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>0.045258</td>\n",
       "      <td>0.107513</td>\n",
       "      <td>0.218201</td>\n",
       "      <td>0.236877</td>\n",
       "      <td>0.048523</td>\n",
       "      <td>0.066620</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.082336</td>\n",
       "      <td>0.122803</td>\n",
       "      <td>-0.142975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190033</td>\n",
       "      <td>0.139526</td>\n",
       "      <td>0.173462</td>\n",
       "      <td>0.205536</td>\n",
       "      <td>0.119934</td>\n",
       "      <td>0.027863</td>\n",
       "      <td>0.125397</td>\n",
       "      <td>0.115784</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.121704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>0.075256</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.202332</td>\n",
       "      <td>0.232513</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.073944</td>\n",
       "      <td>0.051666</td>\n",
       "      <td>0.075867</td>\n",
       "      <td>0.127960</td>\n",
       "      <td>-0.137512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191040</td>\n",
       "      <td>0.127045</td>\n",
       "      <td>0.179077</td>\n",
       "      <td>0.205536</td>\n",
       "      <td>0.118439</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>0.140137</td>\n",
       "      <td>0.108948</td>\n",
       "      <td>0.103638</td>\n",
       "      <td>0.121704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>0.062256</td>\n",
       "      <td>0.103912</td>\n",
       "      <td>0.202728</td>\n",
       "      <td>0.211121</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.083618</td>\n",
       "      <td>0.062531</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>0.126740</td>\n",
       "      <td>-0.132446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.133820</td>\n",
       "      <td>0.161255</td>\n",
       "      <td>0.205353</td>\n",
       "      <td>0.129669</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.138275</td>\n",
       "      <td>0.104614</td>\n",
       "      <td>0.109711</td>\n",
       "      <td>0.128876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.209686</td>\n",
       "      <td>0.195923</td>\n",
       "      <td>0.059692</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>0.051422</td>\n",
       "      <td>0.085907</td>\n",
       "      <td>0.115845</td>\n",
       "      <td>-0.130035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180969</td>\n",
       "      <td>0.125763</td>\n",
       "      <td>0.136597</td>\n",
       "      <td>0.205750</td>\n",
       "      <td>0.133911</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.098419</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.103058</td>\n",
       "      <td>0.129791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>0.044098</td>\n",
       "      <td>0.098175</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>0.054474</td>\n",
       "      <td>0.072754</td>\n",
       "      <td>0.040314</td>\n",
       "      <td>0.087372</td>\n",
       "      <td>0.111023</td>\n",
       "      <td>-0.110992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190033</td>\n",
       "      <td>0.122375</td>\n",
       "      <td>0.221313</td>\n",
       "      <td>0.204956</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>0.024048</td>\n",
       "      <td>0.067474</td>\n",
       "      <td>0.094147</td>\n",
       "      <td>0.094696</td>\n",
       "      <td>0.131348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.058502  0.104431  0.205627  0.064545  0.053528  0.082886  0.028168   \n",
       "1      0.058502  0.104431  0.205627  0.064545  0.053528  0.082886  0.028168   \n",
       "2      0.058380  0.104309  0.205444  0.064423  0.053284  0.082672  0.027893   \n",
       "3      0.058502  0.104431  0.205627  0.064545  0.053528  0.082886  0.028168   \n",
       "4      0.058502  0.104431  0.205627  0.064545  0.053528  0.082886  0.028168   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15995  0.045258  0.107513  0.218201  0.236877  0.048523  0.066620  0.033844   \n",
       "15996  0.075256  0.104431  0.202332  0.232513  0.049469  0.073944  0.051666   \n",
       "15997  0.062256  0.103912  0.202728  0.211121  0.055664  0.083618  0.062531   \n",
       "15998  0.025696  0.100037  0.209686  0.195923  0.059692  0.069214  0.051422   \n",
       "15999  0.044098  0.098175  0.205627  0.176514  0.054474  0.072754  0.040314   \n",
       "\n",
       "             7         8         9   ...        70        71        72  \\\n",
       "0      0.071686  0.096924 -0.126587  ...  0.167664  0.125488  0.181519   \n",
       "1      0.071686  0.096924 -0.126587  ...  0.167664  0.125488  0.181519   \n",
       "2      0.071472  0.096741 -0.126801  ...  0.167419  0.125214  0.181274   \n",
       "3      0.071686  0.096924 -0.126587  ...  0.167664  0.125488  0.181519   \n",
       "4      0.071686  0.096924 -0.126587  ...  0.167664  0.125488  0.181519   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "15995  0.082336  0.122803 -0.142975  ...  0.190033  0.139526  0.173462   \n",
       "15996  0.075867  0.127960 -0.137512  ...  0.191040  0.127045  0.179077   \n",
       "15997  0.076294  0.126740 -0.132446  ...  0.182251  0.133820  0.161255   \n",
       "15998  0.085907  0.115845 -0.130035  ...  0.180969  0.125763  0.136597   \n",
       "15999  0.087372  0.111023 -0.110992  ...  0.190033  0.122375  0.221313   \n",
       "\n",
       "             73        74        75        76        77        78        79  \n",
       "0      0.197449  0.113953  0.062073  0.110046  0.093994  0.100006  0.121033  \n",
       "1      0.197449  0.113953  0.062073  0.110046  0.093994  0.100006  0.121033  \n",
       "2      0.197266  0.113708  0.061646  0.109833  0.093811  0.099823  0.120819  \n",
       "3      0.197449  0.113953  0.062073  0.110046  0.093994  0.100006  0.121033  \n",
       "4      0.197449  0.113953  0.062073  0.110046  0.093994  0.100006  0.121033  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "15995  0.205536  0.119934  0.027863  0.125397  0.115784  0.096985  0.121704  \n",
       "15996  0.205536  0.118439  0.014771  0.140137  0.108948  0.103638  0.121704  \n",
       "15997  0.205353  0.129669  0.000824  0.138275  0.104614  0.109711  0.128876  \n",
       "15998  0.205750  0.133911  0.021515  0.098419  0.101471  0.103058  0.129791  \n",
       "15999  0.204956  0.129181  0.024048  0.067474  0.094147  0.094696  0.131348  \n",
       "\n",
       "[16000 rows x 80 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "separate-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pressing-shelf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15990</th>\n",
       "      <th>15991</th>\n",
       "      <th>15992</th>\n",
       "      <th>15993</th>\n",
       "      <th>15994</th>\n",
       "      <th>15995</th>\n",
       "      <th>15996</th>\n",
       "      <th>15997</th>\n",
       "      <th>15998</th>\n",
       "      <th>15999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.058380</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.058380</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039764</td>\n",
       "      <td>0.072083</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>0.062134</td>\n",
       "      <td>0.040802</td>\n",
       "      <td>0.045258</td>\n",
       "      <td>0.075256</td>\n",
       "      <td>0.062256</td>\n",
       "      <td>0.025696</td>\n",
       "      <td>0.044098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.104309</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.104309</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096191</td>\n",
       "      <td>0.098724</td>\n",
       "      <td>0.103119</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>0.108154</td>\n",
       "      <td>0.107513</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.103912</td>\n",
       "      <td>0.100037</td>\n",
       "      <td>0.098175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.205444</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.205444</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>0.205627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201569</td>\n",
       "      <td>0.205048</td>\n",
       "      <td>0.210449</td>\n",
       "      <td>0.203705</td>\n",
       "      <td>0.215881</td>\n",
       "      <td>0.218201</td>\n",
       "      <td>0.202332</td>\n",
       "      <td>0.202728</td>\n",
       "      <td>0.209686</td>\n",
       "      <td>0.205627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.064423</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.064423</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>0.064545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311005</td>\n",
       "      <td>0.294556</td>\n",
       "      <td>0.277802</td>\n",
       "      <td>0.263885</td>\n",
       "      <td>0.245728</td>\n",
       "      <td>0.236877</td>\n",
       "      <td>0.232513</td>\n",
       "      <td>0.211121</td>\n",
       "      <td>0.195923</td>\n",
       "      <td>0.176514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.053528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>0.045654</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>0.044006</td>\n",
       "      <td>0.042084</td>\n",
       "      <td>0.048523</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.059692</td>\n",
       "      <td>0.054474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.061646</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.061646</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>0.062073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110199</td>\n",
       "      <td>0.094574</td>\n",
       "      <td>0.078522</td>\n",
       "      <td>0.066284</td>\n",
       "      <td>0.044739</td>\n",
       "      <td>0.027863</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.024048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.109833</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.109833</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>0.110046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.123108</td>\n",
       "      <td>0.126038</td>\n",
       "      <td>0.119995</td>\n",
       "      <td>0.113556</td>\n",
       "      <td>0.125397</td>\n",
       "      <td>0.140137</td>\n",
       "      <td>0.138275</td>\n",
       "      <td>0.098419</td>\n",
       "      <td>0.067474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.093811</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.093811</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>0.093994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082489</td>\n",
       "      <td>0.090820</td>\n",
       "      <td>0.102478</td>\n",
       "      <td>0.108948</td>\n",
       "      <td>0.111938</td>\n",
       "      <td>0.115784</td>\n",
       "      <td>0.108948</td>\n",
       "      <td>0.104614</td>\n",
       "      <td>0.101471</td>\n",
       "      <td>0.094147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.099823</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.099823</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>0.100006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106293</td>\n",
       "      <td>0.095459</td>\n",
       "      <td>0.093933</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.090149</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.103638</td>\n",
       "      <td>0.109711</td>\n",
       "      <td>0.103058</td>\n",
       "      <td>0.094696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.121033</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>0.120819</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>0.120819</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>0.121033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123505</td>\n",
       "      <td>0.133820</td>\n",
       "      <td>0.135376</td>\n",
       "      <td>0.129791</td>\n",
       "      <td>0.126190</td>\n",
       "      <td>0.121704</td>\n",
       "      <td>0.121704</td>\n",
       "      <td>0.128876</td>\n",
       "      <td>0.129791</td>\n",
       "      <td>0.131348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 16000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6      \\\n",
       "0   0.058502  0.058502  0.058380  0.058502  0.058502  0.058502  0.058502   \n",
       "1   0.104431  0.104431  0.104309  0.104431  0.104431  0.104431  0.104431   \n",
       "2   0.205627  0.205627  0.205444  0.205627  0.205627  0.205627  0.205627   \n",
       "3   0.064545  0.064545  0.064423  0.064545  0.064545  0.064545  0.064545   \n",
       "4   0.053528  0.053528  0.053284  0.053528  0.053528  0.053528  0.053528   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "75  0.062073  0.062073  0.061646  0.062073  0.062073  0.062073  0.062073   \n",
       "76  0.110046  0.110046  0.109833  0.110046  0.110046  0.110046  0.110046   \n",
       "77  0.093994  0.093994  0.093811  0.093994  0.093994  0.093994  0.093994   \n",
       "78  0.100006  0.100006  0.099823  0.100006  0.100006  0.100006  0.100006   \n",
       "79  0.121033  0.121033  0.120819  0.121033  0.121033  0.121033  0.121033   \n",
       "\n",
       "       7         8         9      ...     15990     15991     15992     15993  \\\n",
       "0   0.058380  0.058502  0.058502  ...  0.039764  0.072083  0.073486  0.062134   \n",
       "1   0.104309  0.104431  0.104431  ...  0.096191  0.098724  0.103119  0.104980   \n",
       "2   0.205444  0.205627  0.205627  ...  0.201569  0.205048  0.210449  0.203705   \n",
       "3   0.064423  0.064545  0.064545  ...  0.311005  0.294556  0.277802  0.263885   \n",
       "4   0.053284  0.053528  0.053528  ...  0.042328  0.045654  0.049011  0.044006   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "75  0.061646  0.062073  0.062073  ...  0.110199  0.094574  0.078522  0.066284   \n",
       "76  0.109833  0.110046  0.110046  ...  0.111267  0.123108  0.126038  0.119995   \n",
       "77  0.093811  0.093994  0.093994  ...  0.082489  0.090820  0.102478  0.108948   \n",
       "78  0.099823  0.100006  0.100006  ...  0.106293  0.095459  0.093933  0.093750   \n",
       "79  0.120819  0.121033  0.121033  ...  0.123505  0.133820  0.135376  0.129791   \n",
       "\n",
       "       15994     15995     15996     15997     15998     15999  \n",
       "0   0.040802  0.045258  0.075256  0.062256  0.025696  0.044098  \n",
       "1   0.108154  0.107513  0.104431  0.103912  0.100037  0.098175  \n",
       "2   0.215881  0.218201  0.202332  0.202728  0.209686  0.205627  \n",
       "3   0.245728  0.236877  0.232513  0.211121  0.195923  0.176514  \n",
       "4   0.042084  0.048523  0.049469  0.055664  0.059692  0.054474  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "75  0.044739  0.027863  0.014771  0.000824  0.021515  0.024048  \n",
       "76  0.113556  0.125397  0.140137  0.138275  0.098419  0.067474  \n",
       "77  0.111938  0.115784  0.108948  0.104614  0.101471  0.094147  \n",
       "78  0.090149  0.096985  0.103638  0.109711  0.103058  0.094696  \n",
       "79  0.126190  0.121704  0.121704  0.128876  0.129791  0.131348  \n",
       "\n",
       "[80 rows x 16000 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "geological-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thousand-pleasure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0585022 , 0.0585022 , 0.05838013, ..., 0.06225586, 0.0256958 ,\n",
       "        0.0440979 ],\n",
       "       [0.10443115, 0.10443115, 0.10430908, ..., 0.10391235, 0.10003662,\n",
       "        0.09817505],\n",
       "       [0.20562744, 0.20562744, 0.20544434, ..., 0.20272827, 0.20968628,\n",
       "        0.20562744],\n",
       "       ...,\n",
       "       [0.09399414, 0.09399414, 0.09381104, ..., 0.10461426, 0.10147095,\n",
       "        0.09414673],\n",
       "       [0.1000061 , 0.1000061 , 0.099823  , ..., 0.10971069, 0.10305786,\n",
       "        0.09469604],\n",
       "       [0.12103271, 0.12103271, 0.12081909, ..., 0.12887573, 0.12979126,\n",
       "        0.13134766]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-pencil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-studio",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-competition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-texture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rubber-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "specialized-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_text, y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "classified-cream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 16000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "pretty-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis=0)\n",
    "\n",
    "x_text = np.expand_dims(x_text, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "worst-watts",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-b5f63f3de136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    297\u001b[0m            [5, 6]])\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (10,)"
     ]
    }
   ],
   "source": [
    "y_train = np.reshape()\n",
    "y_test = np.reshape(1,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "complimentary-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = x_train.reshape(10,10,10,1024)\n",
    "x_text =x_text.reshape(10,10,10,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "compatible-tracker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 62, 15998, 32)     2912      \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 60, 15996, 64)     18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 30, 7998, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 30, 7998, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 15356160)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 15356160)          0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 61424644  \n",
      "=================================================================\n",
      "Total params: 61,446,052\n",
      "Trainable params: 61,446,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 10\n  y sizes: 1\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-b002b91c262a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#Train and Test The Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1047\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1050\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[0;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 10\n  y sizes: 1\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "#Define Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64,16000,10)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "#Compile\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#Train and Test The Model\n",
    "model.fit(x_train, y_train, batch_size=4, epochs=10, verbose=1, validation_data=(x_text, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "absent-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((x_text, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "twelve-stuff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:191 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_12 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [32, 16000]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-ab0018c379e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Display model architecture summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\Asus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:191 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_12 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [32, 16000]\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "model.fit(x_train,y_train)\n",
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_text, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(audio[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "portable-place",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 16000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(audio[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiodf = pd.DataFrame(audio[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "audiodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = audiodf.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-jenny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-final",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
